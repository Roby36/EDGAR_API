{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET-UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ealib\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from typing import List\n",
    "import random\n",
    "from typing import Tuple\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDGAR API requires request header\n",
    "req_header = {\"User-Agent\": \"roberto.brera.24@outlook.com\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "logging.info(\"logging info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to pandas dataframe\n",
    "tickers_df = ealib.get_tickers_df(req_header)\n",
    "tickers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download company filing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cik for some company given name substring\n",
    "query_substr =  \"adeco\"\n",
    "query_ticker = ealib.find_title_substring(tickers_df, query_substr).iloc[0]\n",
    "query_ticker[\"cik_str\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and donwload 20-f\n",
    "curr_comp_mtd = ealib.get_response_dict(ealib.metadata_url(query_ticker[\"cik_str\"]), req_header, mrps=8)\n",
    "curr_filings_df = pd.DataFrame.from_dict(curr_comp_mtd[\"filings\"][\"recent\"])\n",
    "curr_select_filings = ealib.filter_filings(curr_filings_df, \"filingDate\", \"form\", query_forms=[\"20\"], max_days=360)\n",
    "ealib.download_company_filings(req_header, mrps=8, comp_dir=\"Adecoagro S.A. 20-F\", select_filings=curr_select_filings, cik=query_ticker[\"cik_str\"], write_txt=False, write_pdf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: Ticker df (yfinance, e.g. marketCap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose we are iterating through tickers_df\n",
    "curr_ticker = tickers_df.iloc[1000]\n",
    "curr_yticker = yf.Ticker(curr_ticker[\"ticker\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for particular info keys\n",
    "ealib.find_dict_key_substr(curr_yticker.info, [\"cap\"])\n",
    "ealib.find_dict_key_substr(curr_yticker.info, [\"currency\"])\n",
    "\n",
    "# Check other yfinance info, to then compare with SEC\n",
    "ealib.find_keys_containing_all_substrs(curr_yticker.info, [\"cash\", \"operating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the information, returning NA is not found\n",
    "ealib.yf_info(curr_ticker[\"ticker\"], \"marketCap\")\n",
    "ealib.yf_info(curr_ticker[\"ticker\"], \"currency\")\n",
    "ealib.yf_info(curr_ticker[\"ticker\"], \"operatingCashflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate info series for a df of tickers\n",
    "marketCap_series = tickers_df[:10][\"ticker\"].apply(lambda x: ealib.yf_info(x, \"marketCap\"))\n",
    "\n",
    "# How many nans have we got?\n",
    "marketCap_series.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply filtering\n",
    "market_cap_threshhold = 15*(10**9)\n",
    "mask = marketCap_series < market_cap_threshhold\n",
    "filtered_series = marketCap_series[mask]\n",
    "\n",
    "# How many?\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVED search parameters for already-searched company facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "shares_outstanding_query_str = [\"NumberOfSharesOutstanding\", \"EntityCommonStockSharesOutstanding\", \"CommonStockSharesOutstanding\"]\n",
    "ocf_query_str = [\"NetCashProvidedByUsedInOperatingActivities\", \"CashFlowsFromUsedInOperatingActivities\"]\n",
    "# sufficient = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze structure of comp_fact dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_tickers = 100\n",
    "start_ticker = 1000\n",
    "keys_counter = Counter()\n",
    "index_dict = {}\n",
    "for index, row in tickers_df[start_ticker:start_ticker + tot_tickers].iterrows():\n",
    "    \"\"\" \n",
    "    IMPORTANT: Always handle None returns i.e. unsuccessful requests\n",
    "    \"\"\"\n",
    "    cfacts = ealib.get_response_dict(ealib.companyfacts_url(row[\"cik_str\"]), req_header, mrps=8)\n",
    "    if cfacts == None:\n",
    "        keys_counter[\"FAILED_REQS\"] += 1\n",
    "        index_dict[\"FAILED_REQS\"] = index\n",
    "        continue\n",
    "\n",
    "    # Now that we have ascertained that cfacts not None, try to access defensively shares outstanding\n",
    "    shares_out_info = cfacts.get(\"facts\", {}).get(\"dei\", {}).get(\"EntityCommonStockSharesOutstanding\", None)\n",
    "    keys_counter[\"cfacts found BUT SO not found\" if shares_out_info is None else \"cfacts found AND SO found\"] += 1\n",
    "\n",
    "    # Count all the locatable keys in cfacts[\"facts\"]\n",
    "    for key in cfacts[\"facts\"].keys():\n",
    "        keys_counter[key] += 1\n",
    "        index_dict[key] = index\n",
    "\n",
    "print(keys_counter)\n",
    "print(index_dict)\n",
    "print(f'tot_tickers = {tot_tickers}')\n",
    "print(f'us-gaap + ifrs + failed reqs = {keys_counter[\"FAILED_REQS\"] + keys_counter[\"us-gaap\"] + keys_counter[\"ifrs-full\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure to locate & retrieve some arbitrary company fact (testing of comp_fact_df function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with broad list parameters to look for specific keys and then refine search\n",
    "curr_ticker = ealib.find_title_substring(tickers_df, \"adeco\").iloc[0]\n",
    "\n",
    "# Broad search\n",
    "query_fact_substr = [\"seg\"]\n",
    "sufficient = False\n",
    "# Refined search\n",
    "\"\"\"\n",
    "query_fact_substr = [\"NumberOfSharesOutstanding\", \"EntityCommonStockSharesOutstanding\", \"CommonStockSharesOutstanding\"] # Refined list\n",
    "sufficient = True\n",
    "\"\"\"\n",
    "\n",
    "comp_facts = ealib.get_response_dict(ealib.companyfacts_url(curr_ticker[\"cik_str\"]), req_header, 8)\n",
    "if comp_facts is None:\n",
    "    logging.warning(f'Failed request when attempting to retrieve company facts for ticker {curr_ticker[\"ticker\"]}, or comp_facts dictionary empty')\n",
    "\n",
    "# Extract desired company fact\n",
    "res = ealib.comp_facts_df(\n",
    "    comp_facts,\n",
    "    query_fact_substr, \n",
    "    sufficient,\n",
    ")\n",
    "\n",
    "# Log all matches\n",
    "for units, as_key, match_fact, comp_fact_df in res:\n",
    "    logging.info(f'Results with as_key = {as_key}, match_fact = {match_fact}, units = {units} for test with ticker number {random_number}')\n",
    "    # logging.info(f'\\n\\t{comp_fact_df}')\n",
    "\n",
    "if res:\n",
    "    res_units, res_as_key, res_match_fact, res_comp_fact_df = min(res, key=lambda x: len(x[2]))\n",
    "    # print(f'Shortest match fact tuple selected:\\n\\t as_key = {as_key}, match_fact = {match_fact} for test with ticker number {random_number}\\n\\t {res_comp_fact_df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphing a Company Fact Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"WATT\"\n",
    "\n",
    "desired_match_fact = ['EntityCommonStockSharesOutstanding'] # forces only one fact\n",
    "sufficient = True\n",
    "max_days = 360 # day-range for filings\n",
    "\n",
    "curr_ticker = ealib.find_ticker(tickers_df, ticker).iloc[0]\n",
    "comp_facts = ealib.get_response_dict(ealib.companyfacts_url(curr_ticker[\"cik_str\"]), req_header, 8)\n",
    "if comp_facts is None:\n",
    "    logging.warning(f'Failed request when attempting to retrieve company facts for ticker {curr_ticker[\"ticker\"]}, or comp_facts dictionary empty')\n",
    "\n",
    "# Extract desired company fact\n",
    "res = ealib.comp_facts_df(comp_facts, query_fact_substr=desired_match_fact, sufficient=sufficient)\n",
    "\n",
    "if res:\n",
    "    res_units, res_as_key, res_match_fact, res_comp_fact_df = min(res, key=lambda x: len(x[2]))\n",
    "\n",
    "    # Substr from saved search params\n",
    "    \"\"\"\n",
    "    desired_substr = \"NumberOfSharesOutstanding\"\n",
    "    sel_units, sel_as_key, sel_match_fact, sel_comp_fact_df = [t for t in res if desired_substr.lower() in t[2].lower()][0]\n",
    "    \"\"\"\n",
    "\n",
    "    # Now filter filings dataframe\n",
    "    filt_so_df = ealib.filter_filings(res_comp_fact_df, filing_date_col=\"end\", form_col=\"form\", query_forms=[\"\"], max_days=max_days)\n",
    "    \n",
    "    # Plotting graph:\n",
    "    plt.figure(figsize=(10, 5))  # Set the figure size (optional)\n",
    "    plt.plot( filt_so_df['end'], filt_so_df['val'], marker='o')  # Line plot with markers\n",
    "    plt.title(f'{res_match_fact} for {ticker} Inc.')  # Adding a title to the graph\n",
    "    plt.xlabel('Filing end date')  # Label for the x-axis\n",
    "    plt.ylabel('Reported Number of Shares Outstanding')  # Label for the y-axis\n",
    "    plt.grid(True)  # Enable grid for easier readability\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized Company Fact Retrieval Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then refine the search criteria, and test on larger dataset\n",
    "\n",
    "query_fact_substr = [\"NumberOfSharesOutstanding\", \"EntityCommonStockSharesOutstanding\", \"CommonStockSharesOutstanding\"] # Refined list\n",
    "sufficient = True\n",
    "\n",
    "num_tests = 100\n",
    "len_counter = Counter()\n",
    "for _ in range(num_tests):\n",
    "    random_number = random.randint(1, 10000)\n",
    "    curr_ticker = tickers_df.iloc[random_number]\n",
    "\n",
    "    # Request comp facts dictionary\n",
    "    comp_facts = ealib.get_response_dict(ealib.companyfacts_url(curr_ticker[\"cik_str\"]), req_header, 8)\n",
    "    if comp_facts is None:\n",
    "            logging.warning(f'Failed request when attempting to retrieve company facts for ticker {curr_ticker[\"ticker\"]}, or comp_facts dictionary empty')\n",
    "            len_counter['failed reqs'] += 1\n",
    "\n",
    "    # Extract desired company fact\n",
    "    res = ealib.comp_facts_df(\n",
    "        comp_facts,\n",
    "        query_fact_substr, \n",
    "        sufficient,\n",
    "    )\n",
    "    # Record the number of matches\n",
    "    len_counter[f'{len(res)}'] += 1\n",
    "\n",
    "    for units, as_key, match_fact, comp_fact_df in res:\n",
    "        logging.info(f'Results with as_key = {as_key}, match_fact = {match_fact} for test with ticker number {random_number}')\n",
    "    # Now extract tuple with shortest match_fact\n",
    "    if res:\n",
    "        res_units, res_as_key, res_match_fact, res_comp_fact_df = min(res, key=lambda x: len(x[2]))\n",
    "        # Optionally print it out\n",
    "        \"\"\"\n",
    "        print(f'Shortest match fact tuple selected:\\n\\t as_key = {as_key}, match_fact = {match_fact} for test with ticker number {random_number}\\n\\t {res_comp_fact_df}')\n",
    "        \"\"\"\n",
    "\n",
    "print(len_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating cash burn rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking cash burn rateresults on a few tickers\n",
    "test_ticker_str = \"AAPL\"\n",
    "max_days = 180\n",
    "\n",
    "comp_facts = ealib.get_response_dict(ealib.companyfacts_url(ealib.find_ticker(tickers_df, test_ticker_str)[\"cik_str\"].iloc[0]), req_header, 8)\n",
    "if comp_facts is None:\n",
    "        logging.warning(f'Failed request when attempting to retrieve company facts for ticker {curr_ticker[\"ticker\"]}')\n",
    "\n",
    "# Extract desired company fact\n",
    "res = ealib.comp_facts_df(\n",
    "    comp_facts,\n",
    "    [\"NetCashProvidedByUsedInOperatingActivities\", \"CashFlowsFromUsedInOperatingActivities\"], \n",
    "    True\n",
    ")\n",
    "\n",
    "if res:\n",
    "    res_units, res_as_key, res_match_fact, res_comp_fact_df = min(res, key=lambda x: len(x[2]))\n",
    "    ocf_df_filt = ealib.filter_filings(res_comp_fact_df, filing_date_col=\"filed\", form_col=\"form\", query_forms=[\"\"], max_days=max_days)\n",
    "    print(ealib.ocf_average_daily_burn_rate(ocf_df_filt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting between currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_currency = \"USD\"\n",
    "to_currency = \"USD\"\n",
    "forex_ticker =  f\"{from_currency}{to_currency}=X\"\n",
    "\n",
    "ealib.yf_info(forex_ticker, \"previousClose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall filtering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main parameter setting and fucntion call\n",
    "comp_out_df, missing_data_df = ealib.screen_select_companies(\n",
    "    # general parameters:\n",
    "        req_header=req_header, \n",
    "        mrps=8, \n",
    "        tickers_df=tickers_df, \n",
    "        root_dir=\"Selected filings\", \n",
    "    # filtering parameters:\n",
    "        query_forms = [\"424B5\", \"S-3\"], \n",
    "        max_days = 180, \n",
    "        max_market_cap = 15*(10**9), \n",
    "        max_ocf_daily_burn_rate = 0, \n",
    "        ocf_max_days = 180, \n",
    "        ocf_filing_date_col = \"filed\",\n",
    "    # download parameters:\n",
    "        out_df_sort_key = \"Avg yearly OCF burn / Market Cap\", \n",
    "        write_txt = False, \n",
    "        write_pdf = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel\n",
    "file_name = \"Selected filings.xlsx\"\n",
    "with pd.ExcelWriter(file_name, engine='openpyxl') as writer:\n",
    "    # Write each DataFrame to a different sheet\n",
    "    comp_out_df.to_excel(writer, sheet_name='Verified Companies', index=False)\n",
    "    missing_data_df.to_excel(writer, sheet_name='Companies with missing data', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Reconstruct with yfinance missing_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract the original ticker\n",
    "missing_data_ticks = missing_data_df[\"CIQ ticker\"].apply(lambda x: x.split(\":\")[1] if \":\" in x else x)\n",
    "missing_data_ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute OCF with yfinance\n",
    "operatingCashflow_series = missing_data_ticks.apply(lambda x: ealib.yf_info(x, \"operatingCashflow\"))\n",
    "\n",
    "# How many Nones have we still got?\n",
    "operatingCashflow_series.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write enriched data frame back to Excel\n",
    "operatingCashflow_series.name = \"OCF (yf)\"\n",
    "enriched_df = pd.concat([missing_data_df, operatingCashflow_series], axis=1)\n",
    "enriched_df.to_excel(\"enriched missing data.xlsx\", sheet_name='Enriched missing data (yf)', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: remove pharma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Selected filings companies 18-07-24 copy.xlsx\"\n",
    "header_row = 1\n",
    "\n",
    "with pd.ExcelFile(file_name, engine='openpyxl') as reader:\n",
    "    # Retrieve each DataFrame from the respective sheet\n",
    "    comp_out_df = pd.read_excel(reader, sheet_name='Verified Companies', header=header_row)\n",
    "    missing_data_df = pd.read_excel(reader, sheet_name='Companies with missing data', header=header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframes\n",
    "comp_out_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "missing_data_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct original tickers\n",
    "comp_out_df[\"ticker\"] = comp_out_df[\"CIQ ticker\"].apply(lambda x: x.split(\":\")[1] if \":\" in x else x)\n",
    "missing_data_df[\"ticker\"] = missing_data_df[\"CIQ ticker\"].apply(lambda x: x.split(\":\")[1] if \":\" in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sic codes, and add as new columns\n",
    "def get_sic(tickers_df, ticker, req_header, mrps):\n",
    "    found_ticker = ealib.find_ticker(tickers_df, ticker)\n",
    "    if found_ticker.empty:\n",
    "        return None  # or some default value or error handling\n",
    "    return ealib.get_response_dict(ealib.metadata_url(found_ticker.iloc[0][\"cik_str\"]), req_header, mrps=mrps)[\"sic\"]\n",
    "\n",
    "comp_out_df[\"sid\"] = comp_out_df[\"ticker\"].apply(lambda ticker: get_sic(tickers_df, ticker, req_header, 8))\n",
    "missing_data_df[\"sid\"] = missing_data_df[\"ticker\"].apply(lambda ticker: get_sic(tickers_df, ticker, req_header, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First save to Excel with still all companies\n",
    "with pd.ExcelWriter(\"Select Comps with sic.xlsx\", engine='openpyxl') as writer:\n",
    "    # Write each DataFrame to a different sheet\n",
    "    comp_out_df.to_excel(writer, sheet_name='Verified Companies', index=False)\n",
    "    missing_data_df.to_excel(writer, sheet_name='Companies with missing data', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_out_df.rename(columns={\"sid\": \"sic\"}, inplace=True)\n",
    "missing_data_df.rename(columns={\"sid\": \"sic\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many Nans? \n",
    "comp_out_df_na_percentage     = comp_out_df[\"sic\"].isna().mean() * 100\n",
    "missing_data_df_na_percentage = missing_data_df[\"sic\"].isna().mean() * 100\n",
    "\n",
    "logging.info(f\"Percentage of NA/NaN/None values in comp_out_df['sic']: {comp_out_df_na_percentage:.2f}%\")\n",
    "logging.info(f\"Percentage of NA/NaN/None values in missing_data_df['sic']: {missing_data_df_na_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counters for combined dataframes\n",
    "sic_counter = Counter()\n",
    "\n",
    "for index, row in pd.concat([comp_out_df, missing_data_df], ignore_index=True).iterrows():\n",
    "    sic_counter[f\"{row['sic']}\"] += 1\n",
    "\n",
    "# Print results\n",
    "for key, value in sic_counter.items():\n",
    "    print(f\"{key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings whose combined occurrence you want to find\n",
    "pharma_biotech_sic_codes = [\n",
    "    '2833', '2834', '2835', '2836', '8731', '8734', '3841', '3842', '3845'\n",
    "]\n",
    "\n",
    "comp_out_df_filt     = comp_out_df[~comp_out_df['sic'].isin(pharma_biotech_sic_codes)]\n",
    "missing_data_df_filt = missing_data_df[~missing_data_df['sic'].isin(pharma_biotech_sic_codes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write back to Excel after processing:\n",
    "file_name = \"No pharma&biotech Select Comps.xlsx\"\n",
    "with pd.ExcelWriter(file_name, engine='openpyxl') as writer:\n",
    "    # Write each DataFrame to a different sheet\n",
    "    comp_out_df_filt.to_excel(writer, sheet_name='Verified Companies', index=False)\n",
    "    missing_data_df_filt.to_excel(writer, sheet_name='Companies with missing data', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: Change in Company Fact over time (e.g. common shares outstanding percent increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"No pharma&biotech Select Comps.xlsx\"\n",
    "header_row = 0\n",
    "\n",
    "with pd.ExcelFile(file_name, engine='openpyxl') as reader:\n",
    "    # Retrieve each DataFrame from the respective sheet\n",
    "    comp_out_df = pd.read_excel(reader, sheet_name='Verified Companies', header=header_row)\n",
    "    missing_data_df = pd.read_excel(reader, sheet_name='Companies with missing data', header=header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply on whole dataframes \n",
    "def perc_change_shares_out(tickers_df, ticker, req_header, mrps):\n",
    "    found_ticker = ealib.find_ticker(tickers_df, ticker)\n",
    "    if found_ticker.empty:\n",
    "        return None \n",
    "    comp_facts = ealib.get_response_dict(ealib.companyfacts_url(found_ticker.iloc[0][\"cik_str\"]), req_header, mrps)\n",
    "    if comp_facts is None:\n",
    "        logging.warning(f'Failed request when attempting to retrieve company facts for ticker {found_ticker[\"ticker\"]}, or comp_facts dictionary empty')\n",
    "    # Extract desired company fact\n",
    "    res = ealib.comp_facts_df(\n",
    "        comp_facts, \n",
    "        query_fact_substr=[\"NumberOfSharesOutstanding\", \"EntityCommonStockSharesOutstanding\", \"CommonStockSharesOutstanding\"], \n",
    "        sufficient=True\n",
    "    )\n",
    "    # Iterate through all the matched facts and their dataframes\n",
    "    return ealib.comp_fact_avg_change(res, 180, 360)\n",
    "\n",
    "comp_out_df[\"% change in shares outstanding (~6 months)\"] = comp_out_df[\"ticker\"].apply(lambda ticker: perc_change_shares_out(tickers_df, ticker, req_header, 8))\n",
    "missing_data_df[\"% change in shares outstanding (~6 months)\"] = missing_data_df[\"ticker\"].apply(lambda ticker: perc_change_shares_out(tickers_df, ticker, req_header, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many nans?\n",
    "comp_out_df_na_percentage     = comp_out_df[\"% change in shares outstanding (~6 months)\"].isna().mean() * 100\n",
    "missing_data_df_na_percentage = missing_data_df[\"% change in shares outstanding (~6 months)\"].isna().mean() * 100\n",
    "\n",
    "logging.info(f\"Percentage of NA/NaN/None values in comp_out_df['% change in shares outstanding (~6 months)']: {comp_out_df_na_percentage:.2f}%\")\n",
    "logging.info(f\"Percentage of NA/NaN/None values in missing_data_df['% change in shares outstanding (~6 months)']: {missing_data_df_na_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move non verifiable data to missing_data_df\n",
    "missing_data_df = pd.concat([missing_data_df, comp_out_df[comp_out_df['sic'].isna()]], ignore_index=True)\n",
    "missing_data_df = pd.concat([missing_data_df, comp_out_df[comp_out_df['% change in shares outstanding (~6 months)'].isna()]], ignore_index=True)\n",
    "\n",
    "comp_out_df = comp_out_df[~comp_out_df['sic'].isna()]\n",
    "comp_out_df = comp_out_df[~comp_out_df['% change in shares outstanding (~6 months)'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep columns with positive change in shares outstanding \n",
    "comp_out_df = comp_out_df[comp_out_df['% change in shares outstanding (~6 months)'] > 0]\n",
    "comp_out_df = comp_out_df.sort_values(by=\"% change in shares outstanding (~6 months)\", ascending=False)\n",
    "comp_out_df[\"sic\"] = comp_out_df[\"sic\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering: market cap > 100mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcap_min = 1*(10**8)\n",
    "comp_out_df = comp_out_df[comp_out_df[\"Market Cap (USD)\"] > mcap_min]\n",
    "missing_data_df = missing_data_df[~(missing_data_df[\"Market Cap (USD)\"] < mcap_min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_out_df = comp_out_df.sort_values(by='Avg yearly OCF burn / Market Cap', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save back to Excel\n",
    "file_name = \"Updated Screening 19-07-2024.xlsx\"\n",
    "with pd.ExcelWriter(file_name, engine='openpyxl') as writer:\n",
    "    comp_out_df.to_excel(writer, sheet_name='Verified Companies', index=False)\n",
    "    missing_data_df.to_excel(writer, sheet_name='Companies with missing data', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPANY CONCEPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_concept = ealib.get_response_dict(\n",
    "    ealib.companyconcept_url(query_cik, \"/us-gaap/Revenues\"), \n",
    "    req_header,\n",
    "    mrps=mrps\n",
    ")\n",
    "\n",
    "# Coincides with company facts request\n",
    "pd.DataFrame(rev_concept[\"units\"][\"USD\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
